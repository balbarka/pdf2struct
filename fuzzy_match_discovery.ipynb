{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2757a8ee-ac35-42f3-987e-381d6869168a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "As part of the pdf to struct transform there will be cases of intities being close but not matching that we will want to account for.\n",
    "\n",
    "Here is some ref code that reuses our existing simple batch. Given that the fuzzy match will likely be limited to evaluation over a mini-batch, we'll write the method to work with pandas dataframes. \n",
    "\n",
    "**NOTE**: In practice, it is better to fuzzy match to a UID of an individual instead of a fuzzy match to only records within a mini-batch. \n",
    "\n",
    "---\n",
    "\n",
    "The function below isn't a UDF, but rather a function that takes a Spark Dataframe and locally creates a Broadcast spark dataframe. The intention of writing this way is to isolate the fuzzy match logic so that it can be improved upon in future iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e40e72a-4c84-4856-8c12-092099bc13de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install rapidfuzz\n",
    "dbutils.library.restartPython() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a68acad-f097-4800-a3cb-1800ba159b91",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrame\n",
    "from rapidfuzz import process\n",
    "from pyspark.sql.functions import broadcast\n",
    "\n",
    "def broadcast_fuzzy_map(pdf: DataFrame) -> DataFrame:\n",
    "    # Requires that there is a column named `xtract`\n",
    "    pdf = pdf.select(\"extract\").toPandas().drop_duplicates()\n",
    "    pdf['fullname'] = pdf.extract.apply(lambda x: f\"{x['firstname']} {x['lastname']}\")\n",
    "\n",
    "    fullname_map = {r.fullname: r.extract for r in pdf.itertuples()}\n",
    "    fuzzy_keys = set()\n",
    "    fuzzy_vals = []\n",
    "\n",
    "    for row in pdf.itertuples(index=True):\n",
    "        best_match = process.extractOne(row.fullname, fuzzy_keys)\n",
    "        if best_match is None or best_match[1] < 85:\n",
    "            # No quality match found, will map to self:\n",
    "            fuzzy_vals.append(row.extract)\n",
    "        else:\n",
    "            # Quality match found, will map to best matching extract\n",
    "            fuzzy_vals.append(fullname_map.get(best_match[0], row.extract))\n",
    "        fuzzy_keys.add(row.fullname)\n",
    "\n",
    "    pdf['fuzzy_match'] = fuzzy_vals\n",
    "    pdf = pdf.drop(columns=['fullname'])\n",
    "\n",
    "    return broadcast(spark.createDataFrame(pdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b269a40-0d29-4bce-851d-daaeb801d436",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dat = broadcast_fuzzy_map(spark.table(\"main.default.pdf_content\"))\n",
    "dat_matched = spark.table(\"main.default.pdf_content\").join(broadcast(dat), \n",
    "                                                           on=\"extract\", \n",
    "                                                           how=\"left\")\n",
    "display(dat_matched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d29ffd4-5e17-45b8-b6eb-3f36c84546b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Left for potential troubleshooting\n",
    "# Note this process assumes that the first name will be the prefered name, this logic needs to be verified as it will create issues if not a valid assumption.\n",
    "# This method will also create risk of a three way name assignment, not mapping to one value\n",
    "\n",
    "pdf = spark.table(\"main.default.pdf_content\").select(\"extract\").toPandas().drop_duplicates()\n",
    "pdf['fullname'] = pdf.extract.apply(lambda x: f\"{x['firstname']} {x['lastname']}\")\n",
    "\n",
    "fullname_map = {r.fullname: r.extract for r in pdf.itertuples()}\n",
    "fuzzy_keys = set()\n",
    "fuzzy_vals = []\n",
    "\n",
    "for row in pdf.itertuples(index=True):\n",
    "    best_match = process.extractOne(row.fullname, fuzzy_keys)\n",
    "    #print(\"fullname: \" + str(row.fullname))\n",
    "    #print(\"fuzzy_keys: \" + str(fuzzy_keys))\n",
    "    #print(\"best_match: \" + str(best_match))\n",
    "    if best_match is None or best_match[1] < 85:\n",
    "        # No quality match found, will map to self:\n",
    "        fuzzy_vals.append(row.extract)\n",
    "    else:\n",
    "        # Quality match found, will map to best matching extract\n",
    "        fuzzy_vals.append(fullname_map.get(best_match[0], row.extract))\n",
    "    fuzzy_keys.add(row.fullname)\n",
    "    #print(\"\\nXXXXXXXXXXXXX\\n\")\n",
    "\n",
    "pdf['fuzzy_match'] = fuzzy_vals\n",
    "\n",
    "display(pdf)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6094272816247236,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "fuzzy_match_discovery",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
